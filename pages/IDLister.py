import streamlit as st
import zipfile
import os
import tempfile
import pdfplumber
import pandas as pd
import re


st.title("ğŸ“„ PDFå¸³ç¥¨æŠ½å‡ºãƒ„ãƒ¼ãƒ«ï¼ˆ35é …ç›®å¯¾å¿œï¼‰")
st.markdown("ZIPãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPDFè¤‡æ•°å…¥ã‚Šï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€å¿…è¦ãªæƒ…å ±ã‚’CSVã§å‡ºåŠ›ã—ã¾ã™ã€‚")

# æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ35é …ç›®ï¼‰
patterns = {
    "è¼¸å…¥è¨±å¯æ—¥": r"(?:è¼¸å…¥è¨±å¯æ—¥|å¯©æŸ»çµ‚äº†æ—¥)[\s:ï¼š]*([0-9]{4}/[0-9]{1,2}/[0-9]{1,2})",
    "è¼¸å…¥ç”³å‘Šç•ªå·": r"ç”³\s*å‘Š\s*ç•ª\s*å·[^\n]*\n[^\n]*?([0-9ï¼-ï¼™]{3})(?:\s|\n|ã€€|\-)*([0-9ï¼-ï¼™]{4})(?:\s|\n|ã€€|\-)*([0-9ï¼-ï¼™]{4})",
    "è·é€äºº": r"ä»•\s*å‡º\s*äºº[\s:ï¼š\-]*([^\n]+)",
    "ç´ç¨é¡åˆè¨ˆ": r"ç´ç¨é¡åˆè¨ˆ[\s:ï¼šÂ¥\\]*([\d,]+)",
    "ã‚¤ãƒ³ãƒœã‚¤ã‚¹ç•ªå·": r"(FX[0-9]{4,}/[0-9A-Z]+)",
    "ä»•å…¥æ›¸ä¾¡æ ¼": r"A\s*-\s*CIF\s*-\s*USD\s*-\s*([\d\.]+)",
    "å“å": r"å“å[\s:ï¼š]*([^\n]+)",
    "åŸç”£å›½": r"åŸç”£åœ°[\s:ï¼š]*([A-Z]+)",
    "ä»•å…¥æ›¸ç•ªå·": r"ç”³å‘Šç•ªå·[\s:ï¼š]*([0-9 ]{10,})",
    "é€šé–¢é‡‘é¡ï¼ˆCIFï¼‰": r"ç”³å‘Šä¾¡æ ¼ï¼ˆï¼£ï¼©ï¼¦ï¼‰[\s:ï¼šÂ¥\\]*([\d,]+)",
    "ã‚ã¦å…ˆç¨é–¢": r"ã‚ã¦å…ˆç¨é–¢[\s:ï¼š]*([A-Z]+)",
    "ä»£ç†äºº": r"ä»£ç†äºº[\s:ï¼š]*([^\n]+)",
    "è²¨ç‰©å€‹æ•°": r"è²¨ç‰©å€‹æ•°[\s:ï¼š]*([0-9]+)",
    "è²¨ç‰©é‡é‡": r"è²¨ç‰©é‡é‡[\s:ï¼š]*([\d\.]+)",
    "ä»•å…¥æ›¸ä¾¡æ ¼ã®ã‚¿ãƒ¼ãƒ ": r"A\s*-\s*([A-Z]+)\s*-\s*USD\s*-\s*[\d\.]+",
    "é€šé–¢é‡‘é¡ã®é€šè²¨": r"A\s*-\s*[A-Z]+\s*-\s*([A-Z]{3})\s*-\s*[\d\.]+",
    "ç”³å‘Šç•ªå·": r"ç”³å‘Šç•ªå·[\s:ï¼š]*([0-9 ]{10,})",
    "è¼¸å…¥è€…": r"è¼¸\s*å…¥\s*è€…[\s:ï¼š\-]*([^\n]+)",
    "è¼¸å…¥è€…ä½æ‰€": r"è¼¸\s*å…¥\s*è€…[\s:ï¼š\-]*[^\n]+\n([^\n]+)",
    "ä»•å‡ºäººä½æ‰€": r"ä»•\s*å‡º\s*äºº[\s:ï¼š\-]*[^\n]+\n([^\n]+)",
    "AWBç•ªå·": r"ï¼¡ï¼·ï¼¢ç•ªå·[\s:ï¼š\-]*([^\n]+)",
    "MAWBç•ªå·": r"ï¼­ï¼¡ï¼·ï¼¢ç•ªå·[\s:ï¼š\-]*([^\n]+)",
    "ç©å‡ºæ¸¯": r"ç©\s*å‡º\s*æ¸¯[\s:ï¼š\-]*([^\n]+)",
    "å–å¸æ¸¯": r"å–\s*å¸\s*æ¸¯[\s:ï¼š\-]*([^\n]+)",
    "ç©è¼‰æ©Ÿå": r"è¼‰\s*æ©Ÿ\s*å[\s:ï¼š\-]*([^\n]+)",
    "å…¥æ¸¯å¹´æœˆæ—¥": r"å…¥æ¸¯å¹´æœˆæ—¥[\s:ï¼š\-]*([0-9]{4}/[0-9]{1,2}/[0-9]{1,2})",
    "é–¢ç¨": r"é–¢ç¨[\s:ï¼šÂ¥\\]*([\d,]+)",
    "é–¢ç¨æ¬„æ•°": r"é–¢ç¨.*?æ¬„æ•°[\s:ï¼š\-]*([0-9]+)",
    "æ¶ˆè²»ç¨": r"æ¶ˆè²»ç¨[\s:ï¼šÂ¥\\]*([\d,]+)",
    "æ¶ˆè²»ç¨æ¬„æ•°": r"æ¶ˆè²»ç¨.*?æ¬„æ•°[\s:ï¼š\-]*([0-9]+)",
    "åœ°æ–¹æ¶ˆè²»ç¨": r"åœ°æ–¹æ¶ˆè²»ç¨[\s:ï¼šÂ¥\\]*([\d,]+)",
    "åœ°æ–¹æ¶ˆè²»ç¨æ¬„æ•°": r"åœ°æ–¹æ¶ˆè²»ç¨.*?æ¬„æ•°[\s:ï¼š\-]*([0-9]+)",
    "å“ç›®ç•ªå·": r"å“ç›®ç•ªå·[\s:ï¼š]*([A-Z0-9\-\.]+)",
    "é–¢ç¨ç‡": r"é–¢ç¨ç‡[\s:ï¼š]*([0-9\.]+%)",
    "è¨˜äº‹(é€šé–¢)": r"è¨˜äº‹\(é€šé–¢\)[\s:ï¼š\-]*([^\n]+)"
}

uploaded_zip = st.file_uploader("ğŸ“¦ PDFãŒå…¥ã£ãŸZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="zip")

if uploaded_zip:
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, "uploaded.zip")
        with open(zip_path, "wb") as f:
            f.write(uploaded_zip.read())

        # ZIPã‚’è§£å‡
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)

        # # PDFå‡¦ç†
        # results = []
        # for root, _, files in os.walk(temp_dir):
        #     for file in files:
        #         if file.lower().endswith('.pdf'):
        #             file_path = os.path.join(root, file)
        #             with pdfplumber.open(file_path) as pdf:
        #                 text = "\n".join([p.extract_text() or "" for p in pdf.pages])
        #                 row = {"ãƒ•ã‚¡ã‚¤ãƒ«å": file}
        #                 for key, pattern in patterns.items():
        #                     match = re.search(pattern, text)
        #                     row[key] = match.group(1).strip() if match else ""
        #                 results.append(row)

        # PDFå‡¦ç†
        results = []
        for root, _, files in os.walk(temp_dir):
            for file in files:
                if file.lower().endswith('.pdf'):
                    file_path = os.path.join(root, file)
                    try: # Start of the error handling block
                        with pdfplumber.open(file_path) as pdf: # This is the line [1] where the error occurs
                            text = "\n".join([p.extract_text() or "" for p in pdf.pages])
                            row = {"ãƒ•ã‚¡ã‚¤ãƒ«å": file}
                            for key, pattern in patterns.items():
                                match = re.search(pattern, text)
                                row[key] = match.group(1).strip() if match else ""
                        results.append(row)
                    except Exception as e: # Catch any exception that occurs during PDF processing
                        st.warning(f"âš ï¸ Error processing file '{file}': {e}. Skipping this file.")
                         # You can choose to add a placeholder row for the problematic file
                         # For example:
                        # row = {"ãƒ•ã‚¡ã‚¤ãƒ«å": file, "Status": f"Error: {e}"}
                        # results.append(row)
                        continue # Continue to the next file in the loop

        df = pd.DataFrame(results)
        st.success(f"âœ… {len(df)} ä»¶ã®PDFã‹ã‚‰æŠ½å‡ºã—ã¾ã—ãŸã€‚")
        st.dataframe(df)

        # CSVå‡ºåŠ›
        csv = df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button("â¬‡ï¸ æŠ½å‡ºçµæœCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="pdfæŠ½å‡ºä¸€è¦§.csv", mime="text/csv")